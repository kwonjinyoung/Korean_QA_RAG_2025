"""
Qdrant VectorDB í…ŒìŠ¤íŠ¸ ì½”ë“œ
- í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
- ë‹¤ì–‘í•œ ê²€ìƒ‰ ëª¨ë“œ ë¹„êµ
- ê²€ìƒ‰ ê²°ê³¼ í’ˆì§ˆ í‰ê°€
- í•œêµ­ì–´ QA RAG ì‹œìŠ¤í…œ êµ¬í˜„ ë° í‰ê°€
"""

import os
import time
import json
import numpy as np
import re
from typing import List, Dict, Any, Tuple
import signal
from contextlib import contextmanager

from langchain_core.documents import Document
from langchain_qdrant import QdrantVectorStore, RetrievalMode, FastEmbedSparse
from langchain_ollama import OllamaEmbeddings, ChatOllama
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from qdrant_client import QdrantClient
from sklearn.metrics.pairwise import cosine_similarity


class TimeoutException(Exception):
    pass


@contextmanager
def timeout(duration):
    """ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €ë¥¼ ì‚¬ìš©í•œ íƒ€ì„ì•„ì›ƒ ì²˜ë¦¬"""
    def timeout_handler(signum, frame):
        raise TimeoutException(f"ì‘ì—…ì´ {duration}ì´ˆ ë‚´ì— ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    signal.signal(signal.SIGALRM, timeout_handler)
    signal.alarm(duration)
    try:
        yield
    finally:
        signal.alarm(0)


def load_qa_data(file_path: str = "../../RAG/resource/korean_language_rag_V1.0_dev.json") -> List[Dict]:
    """í•œêµ­ì–´ QA ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
    print("ğŸ“š í•œêµ­ì–´ QA ë°ì´í„° ë¡œë“œ ì¤‘...")
    
    if not os.path.exists(file_path):
        raise FileNotFoundError(f"QA ë°ì´í„° íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {file_path}")
    
    with open(file_path, 'r', encoding='utf-8') as f:
        qa_data = json.load(f)
    
    print(f"âœ… QA ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(qa_data)}ê°œ ë¬¸í•­")
    return qa_data


def create_qa_vectorstore(qa_data: List[Dict]) -> QdrantVectorStore:
    """QA ë°ì´í„°ë¡œë¶€í„° ë²¡í„°ìŠ¤í† ì–´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    print("ğŸ”§ QA ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ì¤‘...")
    
    # ì„ë² ë”© ëª¨ë¸ ì„¤ì •
    embeddings = OllamaEmbeddings(
        model="bge-m3",
        base_url="http://localhost:11434"
    )
    
    # Sparse ì„ë² ë”© ì„¤ì •
    sparse_embeddings = FastEmbedSparse(model_name="Qdrant/bm25")
    
    # ë¬¸ì„œ ìƒì„± (ì§ˆë¬¸-ë‹µë³€ ìŒì„ í•˜ë‚˜ì˜ ë¬¸ì„œë¡œ)
    documents = []
    for item in qa_data:
        question = item["input"]["question"]
        answer = item["output"]["answer"]
        question_type = item["input"]["question_type"]
        
        # ì§ˆë¬¸ê³¼ ë‹µë³€ì„ ê²°í•©í•œ ë¬¸ì„œ ìƒì„±
        content = f"ì§ˆë¬¸: {question}\në‹µë³€: {answer}"
        
        doc = Document(
            page_content=content,
            metadata={
                "id": item["id"],
                "question": question,
                "answer": answer,
                "question_type": question_type,
                "length": len(content)
            }
        )
        documents.append(doc)
    
    # ê³ ìœ í•œ Qdrant DB ê²½ë¡œ ì„¤ì • (ì‹œê°„ ê¸°ë°˜)
    import time
    timestamp = int(time.time())
    db_path = f"./qdrant_qa_db_{timestamp}"
    collection_name = "korean_qa_hybrid"
    
    # í˜¹ì‹œ ê¸°ì¡´ ê²½ë¡œê°€ ìˆë‹¤ë©´ ì‚­ì œ ì‹œë„
    import shutil
    if os.path.exists(db_path):
        try:
            shutil.rmtree(db_path)
            print(f"ê¸°ì¡´ DB ë””ë ‰í† ë¦¬ '{db_path}' ì‚­ì œë¨")
        except Exception as e:
            print(f"ê¸°ì¡´ DB ì‚­ì œ ì‹¤íŒ¨ (ë¬´ì‹œ): {e}")
    
    # í˜¹ì‹œ ëª¨ë¥´ë‹ˆ ì ì‹œ ëŒ€ê¸°
    time.sleep(1)
    
    print(f"DB ê²½ë¡œ: {db_path}")
    
    # í•˜ì´ë¸Œë¦¬ë“œ ë²¡í„°ìŠ¤í† ì–´ ìƒì„± (ë¡œì»¬ íŒŒì¼ ê¸°ë°˜)
    qdrant_store = QdrantVectorStore.from_documents(
        documents,
        embedding=embeddings,
        sparse_embedding=sparse_embeddings,
        path=db_path,  # location ëŒ€ì‹  path ì‚¬ìš©
        collection_name=collection_name,
        retrieval_mode=RetrievalMode.HYBRID,
        vector_name="dense",
        sparse_vector_name="sparse",
    )
    
    # ë²¡í„°ìŠ¤í† ì–´ì˜ ë‚´ë¶€ í´ë¼ì´ì–¸íŠ¸ë¥¼ ì¬ì‚¬ìš© (ì¤‘ë³µ ìƒì„± ë°©ì§€)
    client = qdrant_store.client
    
    print("âœ… QA ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ì™„ë£Œ!")
    return qdrant_store, client, embeddings


def clean_model_output(text: str) -> str:
    """ëª¨ë¸ ì¶œë ¥ì—ì„œ think íƒœê·¸ì™€ ë¶ˆí•„ìš”í•œ ë¶€ë¶„ì„ ì œê±°í•©ë‹ˆë‹¤."""
    if not text:
        return text
    
    original_text = text
    
    # <think>...</think> ë¶€ë¶„ ì œê±° (ë‹¤ì¤‘ ì¤„ í¬í•¨)
    text = re.sub(r'<think>.*?</think>', '', text, flags=re.DOTALL | re.IGNORECASE)
    
    # think íƒœê·¸ê°€ ì˜ëª» ë‹«íŒ ê²½ìš° ì²˜ë¦¬
    text = re.sub(r'<think>.*', '', text, flags=re.DOTALL | re.IGNORECASE)
    
    # ë¶ˆí•„ìš”í•œ ë‹µë³€ ë¼ë²¨ ì œê±°
    text = re.sub(r'^\s*ë‹µë³€:\s*', '', text, flags=re.MULTILINE)
    text = re.sub(r'^\s*\*\*ë‹µë³€:\*\*\s*', '', text, flags=re.MULTILINE)
    
    # ì¶”ê°€ì ì¸ ì •ë¦¬
    text = text.strip()
    
    # ë„ˆë¬´ ì§§ì€ ë‹µë³€ì´ë‚˜ ì˜ë¯¸ì—†ëŠ” ë‹µë³€ì¸ ê²½ìš° ì›ë³¸ì—ì„œ ë‹¤ë¥¸ ë¶€ë¶„ ì°¾ê¸°
    if len(text) < 10 or text in ['...', '..', '.']:
        # ì›ë³¸ì—ì„œ quote ë¶€ë¶„ ì°¾ê¸°
        quote_pattern = r'"[^"]*"[ê°€ê°€]?\s*ì˜³ë‹¤[.]?'
        quote_matches = re.findall(quote_pattern, original_text)
        if quote_matches:
            # ì²« ë²ˆì§¸ quoteì™€ "ì˜³ë‹¤" ë¶€ë¶„ ì‚¬ìš©
            text = quote_matches[0]
            
            # ì´ìœ  ì„¤ëª… ë¶€ë¶„ë„ ì°¾ê¸°
            reason_pattern = r'ì˜³ë‹¤[.]?\s*([^<]*?)(?:\.|$)'
            reason_match = re.search(reason_pattern, original_text)
            if reason_match:
                reason = reason_match.group(1).strip()
                if reason and len(reason) > 5:
                    text += " " + reason
                    if not text.endswith('.'):
                        text += '.'
    
    # ë¹ˆ ì¤„ ì œê±°í•˜ê³  ê¹”ë”í•˜ê²Œ ì •ë¦¬
    lines = []
    for line in text.split('\n'):
        line = line.strip()
        if line and not line.startswith('<'):
            lines.append(line)
    
    text = '\n'.join(lines)
    
    # ì—¬ì „íˆ ë„ˆë¬´ ì§§ì€ ê²½ìš° ê¸°ë³¸ ì‘ë‹µ
    if len(text.strip()) < 5:
        text = "ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    return text


def create_rag_chain(vectorstore: QdrantVectorStore):
    """RAG ì²´ì¸ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    print("ğŸ”— RAG ì²´ì¸ ìƒì„± ì¤‘...")
    
    # Qwen3:32b ëª¨ë¸ ì„¤ì • (think íƒœê·¸ í—ˆìš©)
    llm = ChatOllama(
        model="qwen3:32b",
        base_url="http://localhost:11434",
        temperature=0.1,  # ì ë‹¹í•œ ì°½ì˜ì„± ìœ ì§€
        num_predict=4096*2,  # ì¶œë ¥ í† í° ìˆ˜ ëŒ€í­ ì¦ê°€
        num_ctx=4096*2,     # ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ ëŒ€í­ ì¦ê°€ (í“¨ìƒ· ì˜ˆì‹œ í¬í•¨)
        timeout=90,       # ìš”ì²­ íƒ€ì„ì•„ì›ƒ 90ì´ˆë¡œ ì¦ê°€
    )
    
    # ì§ˆë¬¸ ìœ í˜•ë³„ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜
    type_instructions = {
        "êµì •í˜•": """ë‹¹ì‹ ì€ í•œêµ­ì–´ ì–¸ì–´í•™ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. êµì •í˜• ë¬¸ì œì— ë‹µë³€í•˜ì„¸ìš”.

ë‹¤ìŒì€ êµì •í˜• ë¬¸ì œì˜ ì˜ˆì‹œì…ë‹ˆë‹¤:

ì˜ˆì‹œ 1:
ì§ˆë¬¸: ë‹¤ìŒ ë¬¸ì¥ì—ì„œ ì–´ë¬¸ ê·œë²”ì— ë¶€í•©í•˜ì§€ ì•ŠëŠ” ë¶€ë¶„ì„ ì°¾ì•„ ê³ ì¹˜ê³ , ê·¸ ì´ìœ ë¥¼ ì„¤ëª…í•˜ì„¸ìš”.
"ì˜¤ëŠ˜ì€ í™”ìš”ì¼ ì…ë‹ˆë‹¤."
ë‹µë³€: "ì˜¤ëŠ˜ì€ í™”ìš”ì¼ì…ë‹ˆë‹¤."ê°€ ì˜³ë‹¤. 'ì…ë‹ˆë‹¤'ëŠ” 'ì´ë‹¤'ì˜ í™œìš©í˜•ì´ê³  'ì´ë‹¤'ëŠ” ì„œìˆ ê²© ì¡°ì‚¬ì´ë‹¤. ì¡°ì‚¬ëŠ” í•˜ë‚˜ì˜ ë‹¨ì–´ì´ì§€ë§Œ ìë¦½ì„±ì´ ì—†ê¸° ë•Œë¬¸ì— ì•ë§ì— ë¶™ì—¬ ì“´ë‹¤. ë”°ë¼ì„œ 'í™”ìš”ì¼ì…ë‹ˆë‹¤'ì™€ ê°™ì´ ì•ë§ì— ë¶™ì—¬ ì¨ì•¼ í•œë‹¤.

ì˜ˆì‹œ 2:
ì§ˆë¬¸: ë‹¤ìŒ ë¬¸ì¥ì—ì„œ ì–´ë¬¸ ê·œë²”ì— ë¶€í•©í•˜ì§€ ì•ŠëŠ” ë¶€ë¶„ì„ ì°¾ì•„ ê³ ì¹˜ê³ , ê·¸ ì´ìœ ë¥¼ ì„¤ëª…í•˜ì„¸ìš”.
"ë©´í—ˆ ë…„ì›”ì¼ì„ ê¸°ì…í•´ ì£¼ì„¸ìš”."
ë‹µë³€: "ë©´í—ˆ ì—°ì›”ì¼ì„ ê¸°ì…í•´ ì£¼ì„¸ìš”."ê°€ ì˜³ë‹¤. 'ë…€, ë‡¨, ë‰´, ë‹ˆ'ë¥¼ í¬í•¨í•˜ëŠ” í•œìì–´ ìŒì ˆì€ ë‹¨ì–´ ì²«ë¨¸ë¦¬ì— ì˜¤ë©´ 'ì—¬, ìš”, ìœ , ì´'ì˜ í˜•íƒœë¡œ ì‹¤í˜„ë˜ëŠ”ë° ì´ë¥¼ êµ­ì–´ì˜ ë‘ìŒ ë²•ì¹™ì´ë¼ê³  í•œë‹¤. ë‹¨, ì˜ì¡´ ëª…ì‚¬ëŠ” ì´ëŸ¬í•œ ë‘ìŒ ë²•ì¹™ì´ ì ìš©ë˜ì§€ ì•ŠëŠ”ë‹¤. ë”°ë¼ì„œ 'ì—°ì›”ì¼(å¹´æœˆæ—¥)'ëŠ” 'ë…„ì›”ì¼'ì´ ì•„ë‹Œ 'ì—°ì›”ì¼'ë¡œ ì ëŠ”ë‹¤. í•œí¸ 'å¹´åº¦'ì™€ ê°™ì´ ëª…ì‚¬ë¡œ ì“°ì´ê¸°ë„ í•˜ê³  ì˜ì¡´ ëª…ì‚¬ë¡œ ì“°ì´ê¸°ë„ í•˜ëŠ” í•œìì–´ì˜ ê²½ìš° ëª…ì‚¬ì¼ ë•ŒëŠ” 'ì—°ë„', ì˜ì¡´ ëª…ì‚¬ì¼ ë•ŒëŠ” 'ë…„ë„'ë¡œ ì ëŠ”ë‹¤.

ì»¨í…ìŠ¤íŠ¸:
{context}

ì§ˆë¬¸: {question}

<think> íƒœê·¸ ì•ˆì—ì„œ ë¬¸ì œë¥¼ ë¶„ì„í•œ í›„, ì˜¬ë°”ë¥¸ ë¬¸ì¥ê³¼ ì´ìœ ë¥¼ ì œì‹œí•˜ì„¸ìš”.

ë‹µë³€:""",
        "ì„ íƒí˜•": """ë‹¹ì‹ ì€ í•œêµ­ì–´ ì–¸ì–´í•™ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì„ íƒí˜• ë¬¸ì œì— ë‹µë³€í•˜ì„¸ìš”.

ì°¸ê³ í•  ë‹µë³€ í˜•ì‹:
- ì§ˆë¬¸ì—ì„œ ì œì‹œëœ ì„ íƒì§€ ì¤‘ ì˜¬ë°”ë¥¸ ê²ƒì„ ì„ íƒí•©ë‹ˆë‹¤
- "ì˜¬ë°”ë¥¸ì„ íƒì§€"ê°€ ì˜³ë‹¤. ë¬¸ë²•ì  ê·¼ê±°ë¥¼ ì„¤ëª…í•©ë‹ˆë‹¤.

ì»¨í…ìŠ¤íŠ¸:
{context}

ì§ˆë¬¸: {question}

<think> íƒœê·¸ ì•ˆì—ì„œ ì§ˆë¬¸ì˜ ì„ íƒì§€ë“¤ì„ ë¶„ì„í•œ í›„, ì˜¬ë°”ë¥¸ ë‹µë³€ì„ ì œì‹œí•˜ì„¸ìš”.

ë‹µë³€:"""
    }
    
    # ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ (íƒ€ì…ì´ ëª…ì‹œë˜ì§€ ì•Šì€ ê²½ìš°)
    default_prompt = ChatPromptTemplate.from_template("""
ë‹¹ì‹ ì€ í•œêµ­ì–´ ì–¸ì–´í•™ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ëŒ€í•´ ì •í™•í•œ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.

ì»¨í…ìŠ¤íŠ¸:
{context}

ì§ˆë¬¸: {question}

ë‹µë³€:""")
    
    # ê²€ìƒ‰ê¸° ì„¤ì •
    retriever = vectorstore.as_retriever(
        search_type="similarity",
        search_kwargs={"k": 3}  # ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ë¥¼ ë‹¤ì‹œ 3ê°œë¡œ ì¦ê°€
    )
    
    # ë¬¸ì„œ í¬ë§·íŒ… í•¨ìˆ˜
    def format_docs(docs):
        return "\n\n".join(doc.page_content for doc in docs)
    
    # ì§ˆë¬¸ ìœ í˜•ì„ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜
    def extract_question_type(question: str) -> str:
        """ì§ˆë¬¸ì—ì„œ ìœ í˜•ì„ ì¶”ì¶œí•˜ê±°ë‚˜ íŒ¨í„´ìœ¼ë¡œ íŒë‹¨"""
        # ì„ íƒí˜• íŒ¨í„´ ê°ì§€
        if "{" in question and "}" in question and "/" in question:
            return "ì„ íƒí˜•"
        # êµì •í˜• íŒ¨í„´ ê°ì§€
        elif any(keyword in question for keyword in ["êµì •", "ê³ ì¹˜", "ì˜¬ë°”ë¥´ê²Œ", "ì–´ë¬¸ ê·œë²”", "ë¶€í•©í•˜ì§€ ì•ŠëŠ”"]):
            return "êµì •í˜•"
        # ê¸°ë³¸ê°’
        return "ê¸°ë³¸"
    
    # ë™ì  í”„ë¡¬í”„íŠ¸ ì„ íƒ í•¨ìˆ˜
    def get_dynamic_prompt(inputs):
        question = inputs["question"]
        context = inputs["context"]
        
        # ì§ˆë¬¸ ìœ í˜• ì¶”ì¶œ
        question_type = extract_question_type(question)
        
        if question_type in type_instructions:
            # í•´ë‹¹ ìœ í˜•ì˜ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
            prompt_template = type_instructions[question_type]
            return prompt_template.format(context=context, question=question)
        else:
            # ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
            return default_prompt.format_messages(context=context, question=question)[0].content
    
    # RAG ì²´ì¸ êµ¬ì„± (ë™ì  í”„ë¡¬í”„íŠ¸ ì ìš© + í›„ì²˜ë¦¬ + ì¬ì‹œë„ ë¡œì§)
    from langchain_core.runnables import RunnableLambda
    
    def create_dynamic_chain():
        def process_query(question):
            max_retries = 2  # ìµœëŒ€ 2íšŒ ì¬ì‹œë„
            
            for attempt in range(max_retries + 1):
                try:
                    # 1. ê²€ìƒ‰ ìˆ˜í–‰
                    docs = retriever.invoke(question)
                    context = format_docs(docs)
                    
                    # 2. ë™ì  í”„ë¡¬í”„íŠ¸ ìƒì„±
                    prompt_text = get_dynamic_prompt({"question": question, "context": context})
                    
                    # 3. LLM í˜¸ì¶œ
                    result = llm.invoke(prompt_text)
                    
                    # 4. ê²°ê³¼ ì •ë¦¬ (think íƒœê·¸ ì œê±°)
                    raw_output = result.content if hasattr(result, 'content') else str(result)
                    
                    # ë””ë²„ê¹…ì„ ìœ„í•´ ì›ë³¸ ì¶œë ¥ í™•ì¸
                    if attempt > 0:
                        print(f"    ğŸ”„ ì¬ì‹œë„ {attempt}íšŒì°¨ - ì›ë³¸ ì¶œë ¥ ê¸¸ì´: {len(raw_output)}")
                    
                    cleaned_output = clean_model_output(raw_output)
                    
                    # 5. ì„±ê³µì ì¸ ë‹µë³€ì¸ì§€ í™•ì¸
                    if cleaned_output != "ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤." and len(cleaned_output.strip()) > 10:
                        return cleaned_output
                    elif attempt < max_retries:
                        print(f"    âš ï¸ ë‹µë³€ í’ˆì§ˆ ë¶ˆëŸ‰, ì¬ì‹œë„ ì¤‘... ({attempt + 1}/{max_retries})")
                        # ì¬ì‹œë„ ì‹œ ì•½ê°„ì˜ ë¬´ì‘ìœ„ì„± ì¶”ê°€
                        llm.temperature = min(0.3, llm.temperature + 0.1)
                        continue
                    else:
                        # ìµœì¢… ì‹œë„ì—ì„œë„ ì‹¤íŒ¨ ì‹œ, ì›ë³¸ ì¶œë ¥ì„ ë” ê´€ëŒ€í•˜ê²Œ ì²˜ë¦¬
                        print(f"    ğŸš¨ ìµœì¢… ì‹œë„ ì‹¤íŒ¨, ì›ë³¸ ì¶œë ¥ ì‚¬ìš© ì‹œë„")
                        if len(raw_output.strip()) > 5:
                            # think íƒœê·¸ë§Œ ì œê±°í•˜ê³  ë‚˜ë¨¸ì§€ëŠ” ë³´ì¡´
                            fallback_output = re.sub(r'<think>.*?</think>', '', raw_output, flags=re.DOTALL | re.IGNORECASE)
                            fallback_output = fallback_output.strip()
                            if len(fallback_output) > 10:
                                return fallback_output
                        
                        return cleaned_output  # ë§ˆì§€ë§‰ ìˆ˜ë‹¨
                        
                except Exception as e:
                    print(f"    âŒ ì‹œë„ {attempt + 1} ì‹¤íŒ¨: {e}")
                    if attempt < max_retries:
                        continue
                    else:
                        return "ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
            
            return "ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        return RunnableLambda(process_query)
    
    rag_chain = create_dynamic_chain()
    
    print("âœ… RAG ì²´ì¸ ìƒì„± ì™„ë£Œ!")
    return rag_chain, retriever


def calculate_similarity(text1: str, text2: str, embeddings: OllamaEmbeddings) -> float:
    """ë‘ í…ìŠ¤íŠ¸ ê°„ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
    try:
        print(f"    ğŸ“Š ì„ë² ë”© ê³„ì‚° ì¤‘... (í…ìŠ¤íŠ¸ ê¸¸ì´: {len(text1)}, {len(text2)})")
        
        # íƒ€ì„ì•„ì›ƒì„ ì ìš©í•˜ì—¬ ì„ë² ë”© ê³„ì‚°
        with timeout(30):  # 30ì´ˆ íƒ€ì„ì•„ì›ƒ
            embed1 = embeddings.embed_query(text1)
            print(f"    âœ… ì²« ë²ˆì§¸ ì„ë² ë”© ì™„ë£Œ")
            
            embed2 = embeddings.embed_query(text2)
            print(f"    âœ… ë‘ ë²ˆì§¸ ì„ë² ë”© ì™„ë£Œ")
        
        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
        embed1 = np.array(embed1).reshape(1, -1)
        embed2 = np.array(embed2).reshape(1, -1)
        
        similarity = cosine_similarity(embed1, embed2)[0][0]
        print(f"    âœ… ìœ ì‚¬ë„ ê³„ì‚° ì™„ë£Œ: {similarity:.4f}")
        return similarity
        
    except TimeoutException as te:
        print(f"    â° ì„ë² ë”© ê³„ì‚° íƒ€ì„ì•„ì›ƒ: {te}")
        return 0.0
    except Exception as e:
        print(f"    âŒ ìœ ì‚¬ë„ ê³„ì‚° ì‹¤íŒ¨: {e}")
        return 0.0


def evaluate_rag_performance(rag_chain, qa_data: List[Dict], embeddings: OllamaEmbeddings, 
                           sample_size: int = 10) -> Dict[str, Any]:
    """RAG ì‹œìŠ¤í…œì˜ ì„±ëŠ¥ì„ í‰ê°€í•©ë‹ˆë‹¤."""
    print(f"\nğŸ” RAG ì„±ëŠ¥ í‰ê°€ ì‹œì‘ (ìƒ˜í”Œ í¬ê¸°: {sample_size})")
    print("=" * 80)
    
    # í‰ê°€í•  ìƒ˜í”Œ ì„ íƒ
    import random
    random.seed(42)
    sample_data = random.sample(qa_data, min(sample_size, len(qa_data)))
    
    results = []
    total_similarity = 0
    total_time = 0
    
    for i, item in enumerate(sample_data, 1):
        question = item["input"]["question"]
        correct_answer = item["output"]["answer"]
        question_type = item["input"]["question_type"]
        
        print(f"\nğŸ“ í…ŒìŠ¤íŠ¸ {i}/{sample_size}")
        print(f"ì§ˆë¬¸ ìœ í˜•: {question_type}")
        print(f"ì§ˆë¬¸: {question}")
        print(f"ì •ë‹µ: {correct_answer[:100]}...")
        
        # ì§ˆë¬¸ ìœ í˜• ìë™ ì¶”ì¶œ í™•ì¸
        def extract_question_type_for_eval(question: str) -> str:
            """í‰ê°€ìš© ì§ˆë¬¸ ìœ í˜• ì¶”ì¶œ í•¨ìˆ˜"""
            if "{" in question and "}" in question and "/" in question:
                return "ì„ íƒí˜•"
            elif any(keyword in question for keyword in ["êµì •", "ê³ ì¹˜", "ì˜¬ë°”ë¥´ê²Œ", "ì–´ë¬¸ ê·œë²”", "ë¶€í•©í•˜ì§€ ì•ŠëŠ”"]):
                return "êµì •í˜•"
            return "ê¸°ë³¸"
        
        detected_type = extract_question_type_for_eval(question)
        if detected_type != question_type and detected_type != "ê¸°ë³¸":
            print(f"  ğŸ” ìœ í˜• ê°ì§€: ì‹¤ì œ({question_type}) vs ê°ì§€({detected_type})")
        else:
            print(f"  âœ… ìœ í˜• ê°ì§€ ì„±ê³µ: {question_type}")
        
        # RAGë¡œ ë‹µë³€ ìƒì„±
        print(f"ğŸ¤– RAG ë‹µë³€ ìƒì„± ì¤‘...")
        start_time = time.time()
        
        try:
            # íƒ€ì„ì•„ì›ƒì„ ì ìš©í•˜ì—¬ RAG ë‹µë³€ ìƒì„±
            with timeout(90):  # 90ì´ˆë¡œ íƒ€ì„ì•„ì›ƒ ì—°ì¥ (ë” ìì„¸í•œ ë‹µë³€ ìƒì„±)
                generated_answer = rag_chain.invoke(question)
            
            response_time = time.time() - start_time
            total_time += response_time
            
            print(f"ìƒì„± ë‹µë³€: {generated_answer[:150]}...")
            print(f"ì‘ë‹µ ì‹œê°„: {response_time:.2f}ì´ˆ")
            
            # ìœ ì‚¬ë„ ê³„ì‚°
            print(f"ğŸ“Š ìœ ì‚¬ë„ ê³„ì‚° ì‹œì‘...")
            similarity = calculate_similarity(correct_answer, generated_answer, embeddings)
            total_similarity += similarity
            
            print(f"ìœ ì‚¬ë„ ì ìˆ˜: {similarity:.4f}")
            
            results.append({
                "question_id": item["id"],
                "question": question,
                "question_type": question_type,
                "detected_type": detected_type,
                "correct_answer": correct_answer,
                "generated_answer": generated_answer,
                "similarity": similarity,
                "response_time": response_time
            })
            
        except TimeoutException as te:
            print(f"â° RAG ë‹µë³€ ìƒì„± íƒ€ì„ì•„ì›ƒ: {te}")
            results.append({
                "question_id": item["id"],
                "question": question,
                "question_type": question_type,
                "detected_type": detected_type,
                "correct_answer": correct_answer,
                "generated_answer": f"TIMEOUT: {str(te)}",
                "similarity": 0.0,
                "response_time": 0.0
            })
            
        except Exception as e:
            print(f"âŒ ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {e}")
            results.append({
                "question_id": item["id"],
                "question": question,
                "question_type": question_type,
                "detected_type": detected_type,
                "correct_answer": correct_answer,
                "generated_answer": f"ERROR: {str(e)}",
                "similarity": 0.0,
                "response_time": 0.0
            })
        
        print("-" * 80)
        print(f"âœ… í…ŒìŠ¤íŠ¸ {i}/{sample_size} ì™„ë£Œ")
    
    # ì „ì²´ í†µê³„ ê³„ì‚°
    valid_results = [r for r in results if r["similarity"] > 0]
    avg_similarity = total_similarity / len(valid_results) if valid_results else 0
    avg_response_time = total_time / len(valid_results) if valid_results else 0
    
    evaluation_report = {
        "total_questions": len(sample_data),
        "successful_responses": len(valid_results),
        "success_rate": len(valid_results) / len(sample_data),
        "average_similarity": avg_similarity,
        "average_response_time": avg_response_time,
        "detailed_results": results
    }
    
    return evaluation_report


def print_evaluation_summary(report: Dict[str, Any]):
    """í‰ê°€ ê²°ê³¼ ìš”ì•½ì„ ì¶œë ¥í•©ë‹ˆë‹¤."""
    print("\nğŸ“Š RAG ì„±ëŠ¥ í‰ê°€ ê²°ê³¼")
    print("=" * 50)
    print(f"ì´ ì§ˆë¬¸ ìˆ˜: {report['total_questions']}")
    print(f"ì„±ê³µí•œ ì‘ë‹µ ìˆ˜: {report['successful_responses']}")
    print(f"ì„±ê³µë¥ : {report['success_rate']:.2%}")
    print(f"í‰ê·  ìœ ì‚¬ë„: {report['average_similarity']:.4f}")
    print(f"í‰ê·  ì‘ë‹µ ì‹œê°„: {report['average_response_time']:.2f}ì´ˆ")
    
    # ìœ í˜• ê°ì§€ ì •í™•ë„ ë¶„ì„
    type_detection_accuracy = []
    for result in report["detailed_results"]:
        if result["similarity"] > 0:  # ì„±ê³µí•œ ê²½ìš°ë§Œ
            actual_type = result["question_type"]
            detected_type = result["detected_type"]
            if detected_type != "ê¸°ë³¸":  # ê¸°ë³¸ íƒ€ì…ì´ ì•„ë‹ ê²½ìš°ë§Œ í‰ê°€
                type_detection_accuracy.append(actual_type == detected_type)
    
    if type_detection_accuracy:
        accuracy = sum(type_detection_accuracy) / len(type_detection_accuracy)
        print(f"ìœ í˜• ê°ì§€ ì •í™•ë„: {accuracy:.2%} ({sum(type_detection_accuracy)}/{len(type_detection_accuracy)})")
    
    # ìœ ì‚¬ë„ ë¶„í¬ ë¶„ì„
    similarities = [r["similarity"] for r in report["detailed_results"] if r["similarity"] > 0]
    if similarities:
        print(f"\nìœ ì‚¬ë„ ë¶„í¬:")
        print(f"  ìµœê³ : {max(similarities):.4f}")
        print(f"  ìµœì €: {min(similarities):.4f}")
        print(f"  í‘œì¤€í¸ì°¨: {np.std(similarities):.4f}")
        
        # ì„±ëŠ¥ êµ¬ê°„ë³„ ë¶„í¬
        excellent_quality = len([s for s in similarities if s >= 0.9])
        high_quality = len([s for s in similarities if 0.8 <= s < 0.9])
        medium_quality = len([s for s in similarities if 0.6 <= s < 0.8])
        low_quality = len([s for s in similarities if s < 0.6])
        
        print(f"\nì„±ëŠ¥ êµ¬ê°„ë³„ ë¶„í¬:")
        print(f"  ìµœìš°ìˆ˜ (â‰¥0.9): {excellent_quality}ê°œ ({excellent_quality/len(similarities):.1%})")
        print(f"  ìš°ìˆ˜ (0.8-0.9): {high_quality}ê°œ ({high_quality/len(similarities):.1%})")
        print(f"  ì–‘í˜¸ (0.6-0.8): {medium_quality}ê°œ ({medium_quality/len(similarities):.1%})")
        print(f"  ê°œì„ í•„ìš” (<0.6): {low_quality}ê°œ ({low_quality/len(similarities):.1%})")


def analyze_by_question_type(report: Dict[str, Any]):
    """ì§ˆë¬¸ ìœ í˜•ë³„ ì„±ëŠ¥ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
    print("\nğŸ“ˆ ì§ˆë¬¸ ìœ í˜•ë³„ ì„±ëŠ¥ ë¶„ì„")
    print("=" * 50)
    
    type_stats = {}
    for result in report["detailed_results"]:
        q_type = result["question_type"]
        if q_type not in type_stats:
            type_stats[q_type] = {
                "similarities": [], 
                "times": [], 
                "detection_correct": 0,
                "detection_total": 0,
                "generated_answers": []
            }
        
        if result["similarity"] > 0:
            type_stats[q_type]["similarities"].append(result["similarity"])
            type_stats[q_type]["times"].append(result["response_time"])
            type_stats[q_type]["generated_answers"].append(result["generated_answer"])
            
            # ìœ í˜• ê°ì§€ ì •í™•ë„ ê³„ì‚°
            if result["detected_type"] != "ê¸°ë³¸":
                type_stats[q_type]["detection_total"] += 1
                if result["detected_type"] == q_type:
                    type_stats[q_type]["detection_correct"] += 1
    
    for q_type, stats in type_stats.items():
        if stats["similarities"]:
            avg_sim = np.mean(stats["similarities"])
            avg_time = np.mean(stats["times"])
            count = len(stats["similarities"])
            
            print(f"\nğŸ”¸ {q_type}:")
            print(f"  í‰ê·  ìœ ì‚¬ë„: {avg_sim:.4f}")
            print(f"  í‰ê·  ì‘ë‹µ ì‹œê°„: {avg_time:.2f}ì´ˆ")
            print(f"  ì²˜ë¦¬ëœ ë¬¸í•­ ìˆ˜: {count}ê°œ")
            
            # ìœ í˜• ê°ì§€ ì •í™•ë„
            if stats["detection_total"] > 0:
                detection_rate = stats["detection_correct"] / stats["detection_total"]
                print(f"  ìœ í˜• ê°ì§€ ì •í™•ë„: {detection_rate:.2%} ({stats['detection_correct']}/{stats['detection_total']})")
            
            # í’ˆì§ˆ ë¶„í¬
            excellent = len([s for s in stats["similarities"] if s >= 0.9])
            good = len([s for s in stats["similarities"] if s >= 0.8])
            print(f"  ê³ í’ˆì§ˆ ë‹µë³€(â‰¥0.8): {good}ê°œ ({good/count:.1%})")
            print(f"  ìµœìš°ìˆ˜ ë‹µë³€(â‰¥0.9): {excellent}ê°œ ({excellent/count:.1%})")
            
            # ìƒ˜í”Œ ë‹µë³€ ì¶œë ¥ (ê°€ì¥ ë†’ì€ ìœ ì‚¬ë„)
            if stats["similarities"]:
                best_idx = stats["similarities"].index(max(stats["similarities"]))
                best_answer = stats["generated_answers"][best_idx]
                print(f"  ìµœê³  í’ˆì§ˆ ë‹µë³€ ìƒ˜í”Œ: {best_answer[:100]}...")


def save_evaluation_log(report: Dict[str, Any], qa_data: List[Dict]):
    """í‰ê°€ ê²°ê³¼ë¥¼ JSON ë¡œê·¸ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
    import json
    from datetime import datetime
    
    # íƒ€ì„ìŠ¤íƒ¬í”„ ìƒì„±
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    log_filename = f"rag_evaluation_log_{timestamp}.json"
    
    # ìœ ì‚¬ë„ í†µê³„ ê³„ì‚°
    similarities = [r["similarity"] for r in report["detailed_results"] if r["similarity"] > 0]
    similarity_stats = {
        "max": max(similarities) if similarities else 0,
        "min": min(similarities) if similarities else 0,
        "std": float(np.std(similarities)) if similarities else 0
    }
    
    # ì„±ëŠ¥ ì¹´í…Œê³ ë¦¬ë³„ ë¶„í¬ ê³„ì‚°
    performance_distribution = {
        "excellent": len([s for s in similarities if s >= 0.9]),
        "good": len([s for s in similarities if 0.8 <= s < 0.9]),
        "fair": len([s for s in similarities if 0.6 <= s < 0.8]),
        "poor": len([s for s in similarities if s < 0.6])
    }
    
    # ìœ í˜• ê°ì§€ ì •í™•ë„ ê³„ì‚°
    type_detection_accuracy = []
    for result in report["detailed_results"]:
        if result["similarity"] > 0 and "detected_type" in result:
            actual_type = result["question_type"]
            detected_type = result["detected_type"]
            if detected_type != "ê¸°ë³¸":
                type_detection_accuracy.append(actual_type == detected_type)
    
    detection_accuracy = sum(type_detection_accuracy) / len(type_detection_accuracy) if type_detection_accuracy else 0
    
    # ì§ˆë¬¸ ìœ í˜•ë³„ ë¶„ì„ ê³„ì‚°
    type_analysis = {}
    for result in report["detailed_results"]:
        q_type = result["question_type"]
        if q_type not in type_analysis:
            type_analysis[q_type] = {
                "similarities": [],
                "times": [],
                "count": 0
            }
        
        type_analysis[q_type]["count"] += 1
        if result["similarity"] > 0:
            type_analysis[q_type]["similarities"].append(result["similarity"])
            type_analysis[q_type]["times"].append(result["response_time"])
    
    # ë¡œê·¸ ë°ì´í„° êµ¬ì„±
    log_data = {
        "metadata": {
            "timestamp": datetime.now().isoformat(),
            "total_questions": len(qa_data),
            "evaluation_date": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "model_info": {
                "llm_model": "qwen3:32b",
                "embedding_model": "bge-m3",
                "vector_store": "qdrant_hybrid",
                "retrieval_mode": "hybrid_dense_sparse"
            }
        },
        "overall_performance": {
            "total_questions": report["total_questions"],
            "successful_responses": report["successful_responses"],
            "success_rate": report["success_rate"],
            "average_similarity": report["average_similarity"],
            "average_response_time": report["average_response_time"],
            "type_detection_accuracy": detection_accuracy
        },
        "similarity_distribution": similarity_stats,
        "performance_categories": performance_distribution,
        "question_type_analysis": {},
        "detailed_results": []
    }
    
    # ì§ˆë¬¸ ìœ í˜•ë³„ ë¶„ì„ ì¶”ê°€
    for q_type, stats in type_analysis.items():
        log_data["question_type_analysis"][q_type] = {
            "count": stats["count"],
            "average_similarity": float(np.mean(stats["similarities"])) if stats["similarities"] else 0,
            "average_response_time": float(np.mean(stats["times"])) if stats["times"] else 0,
            "success_rate": len(stats["similarities"]) / stats["count"] if stats["count"] > 0 else 0,
            "high_quality_rate": len([s for s in stats["similarities"] if s >= 0.8]) / len(stats["similarities"]) if stats["similarities"] else 0,
            "excellent_rate": len([s for s in stats["similarities"] if s >= 0.9]) / len(stats["similarities"]) if stats["similarities"] else 0
        }
    
    # ìƒì„¸ ê²°ê³¼ ì¶”ê°€
    for result in report["detailed_results"]:
        detailed_result = {
            "question_id": result["question_id"],
            "question_type": result["question_type"],
            "question": result["question"],
            "expected_answer": result["correct_answer"],
            "generated_answer": result["generated_answer"],
            "similarity_score": result["similarity"],
            "response_time": result["response_time"],
            "success": result["similarity"] > 0,
            "performance_category": get_performance_category(result["similarity"]) if result["similarity"] > 0 else "failed",
            "detected_type": result.get("detected_type", "unknown")
        }
        log_data["detailed_results"].append(detailed_result)
    
    # JSON íŒŒì¼ë¡œ ì €ì¥
    try:
        with open(log_filename, 'w', encoding='utf-8') as f:
            json.dump(log_data, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ’¾ í‰ê°€ ê²°ê³¼ê°€ ë¡œê·¸ íŒŒì¼ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {log_filename}")
        print(f"   - ì´ {len(log_data['detailed_results'])}ê°œ ë¬¸í•­ ê²°ê³¼ ì €ì¥")
        print(f"   - íŒŒì¼ í¬ê¸°: {os.path.getsize(log_filename) / 1024:.1f} KB")
        
    except Exception as e:
        print(f"âŒ ë¡œê·¸ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")


def get_performance_category(similarity: float) -> str:
    """ìœ ì‚¬ë„ ì ìˆ˜ì— ë”°ë¥¸ ì„±ëŠ¥ ì¹´í…Œê³ ë¦¬ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    if similarity >= 0.9:
        return "excellent"
    elif similarity >= 0.8:
        return "good"
    elif similarity >= 0.6:
        return "fair"
    else:
        return "poor"


def show_detailed_comparison(report: Dict[str, Any], top_n: int = 2):
    """ìƒìœ„ Nê°œ ê²°ê³¼ì˜ ìƒì„¸ ë¹„êµë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤."""
    print(f"\nğŸ” ìƒìœ„ {top_n}ê°œ ê²°ê³¼ ìƒì„¸ ë¹„êµ")
    print("=" * 80)
    
    # ìœ ì‚¬ë„ ìˆœìœ¼ë¡œ ì •ë ¬
    valid_results = [r for r in report["detailed_results"] if r["similarity"] > 0]
    sorted_results = sorted(valid_results, key=lambda x: x["similarity"], reverse=True)
    
    for i, result in enumerate(sorted_results[:top_n], 1):
        print(f"\nğŸ† {i}ë“± (ìœ ì‚¬ë„: {result['similarity']:.4f})")
        print(f"ìœ í˜•: {result['question_type']}")
        print(f"ì§ˆë¬¸: {result['question']}")
        print(f"\nì •ë‹µ:")
        print(f"  {result['correct_answer']}")
        print(f"\nìƒì„± ë‹µë³€:")
        print(f"  {result['generated_answer']}")
        print("-" * 80)


def load_existing_vectorstore():
    """ê¸°ì¡´ì— êµ¬ì¶•ëœ Qdrant ë²¡í„°ìŠ¤í† ì–´ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
    print("ğŸ”„ ê¸°ì¡´ Qdrant ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ ì¤‘...")
    
    # DB ê²½ë¡œ í™•ì¸
    db_path = "./qdrant_local_db"
    if not os.path.exists(db_path):
        raise FileNotFoundError(f"Qdrant DBê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {db_path}")
    
    # ì„ë² ë”© ëª¨ë¸ ì„¤ì •
    embeddings = OllamaEmbeddings(
        model="bge-m3",
        base_url="http://localhost:11434"
    )
    
    # Sparse ì„ë² ë”© ì„¤ì •
    sparse_embeddings = FastEmbedSparse(model_name="Qdrant/bm25")
    
    # Qdrant í´ë¼ì´ì–¸íŠ¸ ìƒì„±
    client = QdrantClient(path=db_path)
    
    collection_name = "korean_qa_hybrid"
    
    # ì»¬ë ‰ì…˜ ì¡´ì¬ í™•ì¸
    collections = client.get_collections()
    collection_names = [col.name for col in collections.collections]
    
    if collection_name not in collection_names:
        raise ValueError(f"ì»¬ë ‰ì…˜ '{collection_name}'ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë¨¼ì € makeDB_local_2.pyë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
    
    # í•˜ì´ë¸Œë¦¬ë“œ ë²¡í„°ìŠ¤í† ì–´ ìƒì„±
    qdrant_store = QdrantVectorStore(
        client=client,
        collection_name=collection_name,
        embedding=embeddings,
        sparse_embedding=sparse_embeddings,
        retrieval_mode=RetrievalMode.HYBRID,
        vector_name="dense",
        sparse_vector_name="sparse",
    )
    
    print("âœ… ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ ì™„ë£Œ!")
    return qdrant_store, client, embeddings, sparse_embeddings


def get_collection_info(client: QdrantClient, collection_name: str):
    """ì»¬ë ‰ì…˜ ì •ë³´ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤."""
    print(f"\nğŸ“Š ì»¬ë ‰ì…˜ '{collection_name}' ì •ë³´:")
    
    # ì»¬ë ‰ì…˜ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    collection_info = client.get_collection(collection_name)
    print(f"- ë¬¸ì„œ ìˆ˜: {collection_info.points_count}")
    
    # ì»¬ë ‰ì…˜ ì„¤ì • ì •ë³´ í™•ì¸
    try:
        # ìƒˆë¡œìš´ API ë°©ì‹ ì‹œë„
        if hasattr(collection_info.config, 'params'):
            if hasattr(collection_info.config.params, 'vectors'):
                print(f"- ë²¡í„° ì„¤ì •: {collection_info.config.params.vectors}")
            if hasattr(collection_info.config.params, 'sparse_vectors'):
                print(f"- Sparse ë²¡í„° ì„¤ì •: {collection_info.config.params.sparse_vectors}")
        else:
            # ê¸°ë³¸ ì •ë³´ë§Œ ì¶œë ¥
            print(f"- ì»¬ë ‰ì…˜ ìƒíƒœ: {collection_info.status}")
            print(f"- ì˜µí‹°ë§ˆì´ì € ìƒíƒœ: {collection_info.optimizer_status}")
    except Exception as e:
        print(f"- ìƒì„¸ ì„¤ì • ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        print(f"- ì»¬ë ‰ì…˜ ìƒíƒœ: {collection_info.status}")
        print(f"- ê¸°ë³¸ ì •ë³´ë§Œ í‘œì‹œë©ë‹ˆë‹¤.")


def test_search_modes(vectorstore: QdrantVectorStore, embeddings, sparse_embeddings, client: QdrantClient):
    """ë‹¤ì–‘í•œ ê²€ìƒ‰ ëª¨ë“œë¥¼ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤."""
    print("\nğŸ” ë‹¤ì–‘í•œ ê²€ìƒ‰ ëª¨ë“œ í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    test_queries = [
        "í‘œì¤€ì–´ëŠ” ë¬´ì—‡ì¸ê°€ìš”?",
        "ë³µìˆ˜ í‘œì¤€ì–´ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”",
        "ê°€ë­„ê³¼ ê°€ë¬¼ì€ ê°™ì€ ë§ì¸ê°€ìš”?",
        "í•œêµ­ì–´ ë§ì¶¤ë²• ê·œì¹™ì€ ë¬´ì—‡ì¸ê°€ìš”?",
        "ì–¸ì–´í•™ì  íŠ¹ì§•ì„ ì•Œë ¤ì£¼ì„¸ìš”"
    ]
    
    for query in test_queries:
        print(f"\nğŸ” í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬: '{query}'")
        print("-" * 50)
        
        # 1. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰
        print("1ï¸âƒ£ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (Dense + Sparse)")
        hybrid_store = QdrantVectorStore(
            client=client,
            collection_name="korean_qa_hybrid",
            embedding=embeddings,
            sparse_embedding=sparse_embeddings,
            retrieval_mode=RetrievalMode.HYBRID,
            vector_name="dense",
            sparse_vector_name="sparse",
        )
        
        start_time = time.time()
        hybrid_results = hybrid_store.similarity_search_with_score(query, k=3)
        hybrid_time = time.time() - start_time
        
        print(f"   ê²€ìƒ‰ ì‹œê°„: {hybrid_time:.3f}ì´ˆ")
        for i, (doc, score) in enumerate(hybrid_results, 1):
            print(f"   {i}. [ì ìˆ˜: {score:.4f}] {doc.page_content[:100]}...")
        
        # 2. Dense ê²€ìƒ‰ë§Œ
        print("\n2ï¸âƒ£ Dense ê²€ìƒ‰ë§Œ (ì˜ë¯¸ ê¸°ë°˜)")
        dense_store = QdrantVectorStore(
            client=client,
            collection_name="korean_qa_hybrid",
            embedding=embeddings,
            retrieval_mode=RetrievalMode.DENSE,
            vector_name="dense",
        )
        
        start_time = time.time()
        dense_results = dense_store.similarity_search_with_score(query, k=3)
        dense_time = time.time() - start_time
        
        print(f"   ê²€ìƒ‰ ì‹œê°„: {dense_time:.3f}ì´ˆ")
        for i, (doc, score) in enumerate(dense_results, 1):
            print(f"   {i}. [ì ìˆ˜: {score:.4f}] {doc.page_content[:100]}...")
        
        # 3. Sparse ê²€ìƒ‰ë§Œ
        print("\n3ï¸âƒ£ Sparse ê²€ìƒ‰ë§Œ (í‚¤ì›Œë“œ ê¸°ë°˜ BM25)")
        sparse_store = QdrantVectorStore(
            client=client,
            collection_name="korean_qa_hybrid",
            sparse_embedding=sparse_embeddings,
            retrieval_mode=RetrievalMode.SPARSE,
            sparse_vector_name="sparse",
        )
        
        start_time = time.time()
        sparse_results = sparse_store.similarity_search_with_score(query, k=3)
        sparse_time = time.time() - start_time
        
        print(f"   ê²€ìƒ‰ ì‹œê°„: {sparse_time:.3f}ì´ˆ")
        for i, (doc, score) in enumerate(sparse_results, 1):
            print(f"   {i}. [ì ìˆ˜: {score:.4f}] {doc.page_content[:100]}...")
        
        print("\n" + "="*60)


def test_retriever_functionality(vectorstore: QdrantVectorStore):
    """Retriever ê¸°ëŠ¥ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤."""
    print("\nğŸ”§ Retriever ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    # MMR (Maximal Marginal Relevance) ê²€ìƒ‰
    retriever_mmr = vectorstore.as_retriever(
        search_type="mmr",
        search_kwargs={"k": 5, "fetch_k": 20}
    )
    
    # ìœ ì‚¬ë„ ê¸°ë°˜ ê²€ìƒ‰
    retriever_similarity = vectorstore.as_retriever(
        search_type="similarity",
        search_kwargs={"k": 5}
    )
    
    test_query = "í‘œì¤€ì–´ ê·œì •ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”"
    
    print(f"í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬: '{test_query}'")
    print("\n1ï¸âƒ£ MMR ê²€ìƒ‰ ê²°ê³¼:")
    mmr_results = retriever_mmr.invoke(test_query)
    for i, doc in enumerate(mmr_results, 1):
        print(f"   {i}. {doc.page_content[:150]}...")
        print(f"      ë©”íƒ€ë°ì´í„°: {doc.metadata}")
    
    print("\n2ï¸âƒ£ ìœ ì‚¬ë„ ê²€ìƒ‰ ê²°ê³¼:")
    similarity_results = retriever_similarity.invoke(test_query)
    for i, doc in enumerate(similarity_results, 1):
        print(f"   {i}. {doc.page_content[:150]}...")
        print(f"      ë©”íƒ€ë°ì´í„°: {doc.metadata}")


def test_metadata_filtering(vectorstore: QdrantVectorStore):
    """ë©”íƒ€ë°ì´í„° í•„í„°ë§ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤."""
    print("\nğŸ·ï¸  ë©”íƒ€ë°ì´í„° í•„í„°ë§ í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    from qdrant_client import models
    
    # íŠ¹ì • ê¸¸ì´ ì´ìƒì˜ ë¬¸ì„œë§Œ ê²€ìƒ‰
    print("1ï¸âƒ£ ê¸¸ì´ê°€ 1000ì ì´ìƒì¸ ë¬¸ì„œë§Œ ê²€ìƒ‰:")
    
    results = vectorstore.similarity_search(
        query="í•œêµ­ì–´ í‘œì¤€ì–´",
        k=3,
        filter=models.Filter(
            must=[
                models.FieldCondition(
                    key="metadata.length",
                    range=models.Range(gte=1000)
                )
            ]
        )
    )
    
    for i, doc in enumerate(results, 1):
        print(f"   {i}. ê¸¸ì´: {doc.metadata['length']}ì")
        print(f"      ë‚´ìš©: {doc.page_content[:100]}...")
    
    print("\n2ï¸âƒ£ íŠ¹ì • ID ë²”ìœ„ì˜ ë¬¸ì„œë§Œ ê²€ìƒ‰:")
    results = vectorstore.similarity_search(
        query="ì–¸ì–´ ê·œì¹™",
        k=3,
        filter=models.Filter(
            must=[
                models.FieldCondition(
                    key="metadata.id",
                    range=models.Range(gte=0, lte=10)
                )
            ]
        )
    )
    
    for i, doc in enumerate(results, 1):
        print(f"   {i}. ID: {doc.metadata['id']}")
        print(f"      ë‚´ìš©: {doc.page_content[:100]}...")


def performance_benchmark(vectorstore: QdrantVectorStore):
    """ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
    print("\nâš¡ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬")
    print("=" * 50)
    
    test_queries = [
        "í‘œì¤€ì–´ ê·œì •",
        "í•œêµ­ì–´ ë§ì¶¤ë²•",
        "ì–¸ì–´í•™ ì´ë¡ ",
        "ë¬¸ë²• ê·œì¹™",
        "ì–´íœ˜ ë¶„ë¥˜"
    ]
    
    total_time = 0
    total_queries = len(test_queries)
    
    print(f"ì´ {total_queries}ê°œ ì¿¼ë¦¬ë¡œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì¤‘...")
    
    for i, query in enumerate(test_queries, 1):
        start_time = time.time()
        results = vectorstore.similarity_search(query, k=5)
        query_time = time.time() - start_time
        total_time += query_time
        
        print(f"   ì¿¼ë¦¬ {i}: '{query}' - {query_time:.3f}ì´ˆ ({len(results)}ê°œ ê²°ê³¼)")
    
    avg_time = total_time / total_queries
    print(f"\nğŸ“Š ì„±ëŠ¥ ê²°ê³¼:")
    print(f"   - ì´ ì‹¤í–‰ ì‹œê°„: {total_time:.3f}ì´ˆ")
    print(f"   - í‰ê·  ì¿¼ë¦¬ ì‹œê°„: {avg_time:.3f}ì´ˆ")
    print(f"   - ì´ˆë‹¹ ì¿¼ë¦¬ ìˆ˜: {1/avg_time:.2f} QPS")


def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    try:
        print("ğŸš€ í•œêµ­ì–´ QA RAG ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹œì‘")
        print("=" * 80)
        
        # 1. QA ë°ì´í„° ë¡œë“œ
        qa_data = load_qa_data()
        
        # 2. QA ë²¡í„°ìŠ¤í† ì–´ ìƒì„±
        vectorstore, client, embeddings = create_qa_vectorstore(qa_data)
        
        # 3. RAG ì²´ì¸ ìƒì„±
        rag_chain, retriever = create_rag_chain(vectorstore)
        
        # 4. ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸
        print("\nğŸ§ª ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰")
        test_question = "í‘œì¤€ì–´ëŠ” ë¬´ì—‡ì¸ê°€ìš”?"
        print(f"í…ŒìŠ¤íŠ¸ ì§ˆë¬¸: {test_question}")
        
        try:
            with timeout(30):  # 30ì´ˆ íƒ€ì„ì•„ì›ƒ
                answer = rag_chain.invoke(test_question)
            print(f"ìƒì„±ëœ ë‹µë³€: {answer}")
        except TimeoutException:
            print("â° ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ íƒ€ì„ì•„ì›ƒ - í‰ê°€ë¡œ ë„˜ì–´ê°‘ë‹ˆë‹¤.")
        
        # 5. ì „ì²´ ë°ì´í„°ì…‹ ì„±ëŠ¥ í‰ê°€ ì‹¤í–‰
        print(f"\nğŸ” ì „ì²´ ë°ì´í„°ì…‹ ì„±ëŠ¥ í‰ê°€ ì‹œì‘ (ì´ {len(qa_data)}ê°œ ë¬¸í•­)")
        evaluation_report = evaluate_rag_performance(
            rag_chain, qa_data, embeddings, sample_size=len(qa_data)  # ì „ì²´ ë°ì´í„°ì…‹
        )
        
        # 6. í‰ê°€ ê²°ê³¼ë¥¼ JSON ë¡œê·¸ íŒŒì¼ë¡œ ì €ì¥
        save_evaluation_log(evaluation_report, qa_data)
        
        # 7. í‰ê°€ ê²°ê³¼ ì¶œë ¥
        print_evaluation_summary(evaluation_report)
        analyze_by_question_type(evaluation_report)
        show_detailed_comparison(evaluation_report, top_n=5)  # ìƒìœ„ 5ê°œ ê²°ê³¼ í‘œì‹œ
        
        # 7. ê¸°ì¡´ ë²¡í„°ìŠ¤í† ì–´ í…ŒìŠ¤íŠ¸ëŠ” ìƒëµ
        print("\n" + "="*80)
        print("ğŸ“Š ê¸°ì¡´ ë²¡í„°ìŠ¤í† ì–´ í…ŒìŠ¤íŠ¸ëŠ” ì„±ëŠ¥ìƒì˜ ì´ìœ ë¡œ ìƒëµí•©ë‹ˆë‹¤.")
        
        print("\nâœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        print("í•œêµ­ì–´ QA RAG ì‹œìŠ¤í…œì´ ì •ìƒì ìœ¼ë¡œ ë™ì‘í•˜ê³  ìˆìŠµë‹ˆë‹¤.")
        
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        raise


if __name__ == "__main__":
    main()
